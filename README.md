# Bert-and-multimodal-model-for-visuel-contextuel-text-classification
This project implements a cross-attention-based architecture to enhance BERT with visual features extracted from a Vision Transformer (ViT). The model classifies sentences (and tokens) from artwork-related texts as either visual (about the painting) or contextual (about external knowledge), without requiring the image at inference.

## LAVIS library
We buid our model with the Lavis library: [link to Lavis](https://github.com/valeriatisch/LAVIS/tree/a154d419ce1fc25de772b6c7309bfb927b557701)
Make sure to clone and install it following their instructions in their documentation: [Lavis documentation](https://opensource.salesforce.com/LAVIS//latest/index.html)
